{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f1c38b",
   "metadata": {},
   "source": [
    "# Signal Quality Enhancement in Systematic Trading: A Machine Learning Approach to Refining Technical Indicator Signals\n",
    "\n",
    "**Dissertation**  \n",
    "MSc Artificial Intelligence in Finance  \n",
    "School of Computer Science and Electronic Engineering  \n",
    "University of Essex  \n",
    "\n",
    "**Author:** Dulaj Panapitiya  \n",
    "**Date:** August 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf4219",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup\n",
    "\n",
    "Import all required libraries for data processing, technical analysis, machine learning, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Technical Analysis library\n",
    "import ta\n",
    "\n",
    "# File and OS utilities\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# ML & Visualization\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# LightGBM Classifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45816163",
   "metadata": {},
   "source": [
    "## 2. Supertrend Indicator Calculation\n",
    "\n",
    "Function to compute Supertrend indicator and assign trade IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_supertrend(df_loc):\n",
    "    \"\"\"\n",
    "    Calculate Supertrend indicator and assign position/trade IDs.\n",
    "\n",
    "    Parameters:\n",
    "        df_loc (pd.DataFrame): DataFrame containing columns 'prev_high', 'prev_low', 'prev_close'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added columns for supertrend, trade_id.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate HL2 and ATR(10)\n",
    "    hl2 = (df_loc['prev_high'] + df_loc['prev_low']) / 2\n",
    "    atr10 = ta.volatility.AverageTrueRange(high=df_loc['prev_high'], low=df_loc['prev_low'], \n",
    "                                           close=df_loc['prev_close'], window=10).average_true_range()\n",
    "\n",
    "    # Calculate upper and lower bands (Supertrend 10x3)\n",
    "    upperband = hl2 + (3 * atr10)\n",
    "    lowerband = hl2 - (3 * atr10) \n",
    "\n",
    "    # Initialize arrays for trend, trade ID, and bands\n",
    "    trend = np.full(len(df_loc), np.nan)\n",
    "    trend[0] = 1  # Assume uptrend initially\n",
    "\n",
    "    trade_id = np.full(len(df_loc), np.nan)\n",
    "    trade_id[0] = 0\n",
    "\n",
    "    # Main Supertrend calculation loop\n",
    "    for i in range(1, len(df_loc)):\n",
    "        curr_close = df_loc['prev_close'].iloc[i]\n",
    "        prev_close = df_loc['prev_close'].iloc[i - 1]\n",
    "\n",
    "        # Update trend and bands\n",
    "        if prev_close < upperband.iloc[i - 1]:\n",
    "            upperband.iloc[i] = min(upperband.iloc[i], upperband.iloc[i - 1])\n",
    "        if prev_close > lowerband.iloc[i - 1]:\n",
    "            lowerband.iloc[i] = max(lowerband.iloc[i], lowerband.iloc[i - 1])\n",
    "\n",
    "        # Determine trend direction\n",
    "        if trend[i - 1] == 1:\n",
    "            trend[i] = 1 if curr_close > lowerband.iloc[i - 1] else -1\n",
    "        else:\n",
    "            trend[i] = -1 if curr_close < upperband.iloc[i - 1] else 1\n",
    "\n",
    "        # Assign trade IDs based on trend change\n",
    "        if trend[i - 1] == trend[i]:\n",
    "            trade_id[i] = trade_id[i - 1]\n",
    "        else:\n",
    "            trade_id[i] = trade_id[i - 1] + 1\n",
    "\n",
    "    # Assign results to DataFrame\n",
    "    df_loc['supertrend'] = trend\n",
    "    df_loc['trade_id'] = trade_id\n",
    "\n",
    "    return df_loc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f585664c",
   "metadata": {},
   "source": [
    "## 3. Trade Evaluation Function\n",
    "\n",
    "Assigns trade result labels (Long, Short, Neutral) based on trade return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a53b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_trade(group):\n",
    "    \"\"\"\n",
    "    Evaluate the result of a trade group based on current open and next open (close) prices.\n",
    "\n",
    "    Parameters:\n",
    "        group (pd.DataFrame): DataFrame containing trade data for a single trade_id group.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The input group with 'trade_result' and 'trade_id' columns assigned.\n",
    "    \"\"\"\n",
    "    # Get entry and exit prices for the trade\n",
    "    entry_price = group['open'].iloc[0]\n",
    "    exit_price = group['next_open'].iloc[0]\n",
    "\n",
    "    # Calculate trade return as percentage change\n",
    "    trade_return = (exit_price - entry_price) / entry_price\n",
    "\n",
    "    # Assign trade result label:\n",
    "    # 2 = Long (return > 1%), 0 = Short (return < -1%), 1 = Neutral (otherwise)\n",
    "    if trade_return > 0.01:\n",
    "        result = 2  # Long\n",
    "    elif trade_return < -0.01:\n",
    "        result = 0  # Short\n",
    "    else:\n",
    "        result = 1  # Neutral\n",
    "\n",
    "    # Assign result and trade_id to all rows in the group\n",
    "    group['trade_result'] = result\n",
    "    group['trade_id'] = group.name  # group.name is the trade_id\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0540c6",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Generates technical and statistical features for ML modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df_loc):\n",
    "    \"\"\"\n",
    "    Generate technical and statistical features for ML modeling.\n",
    "\n",
    "    Parameters:\n",
    "        df_loc (pd.DataFrame): DataFrame containing OHLCV columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with engineered features, ready for ML.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Previous trade result feature ---\n",
    "    prev_trade_results = df_loc.groupby('trade_id')['trade_result'].first().shift(1)\n",
    "    prev_trade_result_map = prev_trade_results.to_dict()\n",
    "    df_loc['prev_trade_result'] = df_loc['trade_id'].map(prev_trade_result_map)\n",
    "\n",
    "    # --- Basic Price Features ---\n",
    "    df_loc['return'] = np.log(df_loc['prev_close'] / df_loc['prev_close'].shift(1))\n",
    "    df_loc['range_high_low'] = (df_loc['prev_high'] - df_loc['prev_low']) / df_loc['prev_low']\n",
    "    df_loc['Volatility'] = ((df_loc['prev_close'] - df_loc['prev_open']) / df_loc['prev_open']).rolling(window=20).std()\n",
    "\n",
    "    # --- Z-Score of Price ---\n",
    "    rolling_mean = df_loc['prev_close'].rolling(10).mean()\n",
    "    rolling_std = df_loc['prev_close'].rolling(10).std()\n",
    "    df_loc['zscore_10'] = (df_loc['prev_close'] - rolling_mean) / rolling_std\n",
    "\n",
    "    # --- ADX and Directional Indicators ---\n",
    "    adx = ta.trend.ADXIndicator(high=df_loc['prev_high'], low=df_loc['prev_low'], close=df_loc['prev_close'], window=14)\n",
    "    df_loc['+DI'] = adx.adx_pos()\n",
    "    df_loc['-DI'] = adx.adx_neg()\n",
    "    df_loc['ADX'] = adx.adx()\n",
    "    df_loc['ADX_slope'] = df_loc['ADX'].diff()\n",
    "\n",
    "    # --- MACD ---\n",
    "    macd = ta.trend.MACD(df_loc['prev_close'])\n",
    "    df_loc['MACD_signal'] = macd.macd_diff() / df_loc['prev_close']\n",
    "\n",
    "    # --- Stochastic Oscillator ---\n",
    "    df_loc['Stoch_D'] = ta.momentum.StochasticOscillator(df_loc['prev_high'], df_loc['prev_low'], df_loc['prev_close']).stoch_signal()\n",
    "\n",
    "    # --- Commodity Channel Index (CCI) ---\n",
    "    CCI = ta.trend.CCIIndicator(df_loc['prev_high'], df_loc['prev_low'], df_loc['prev_close']).cci()\n",
    "    df_loc['CCI_zscore'] = (CCI - CCI.rolling(20).mean()) / CCI.rolling(20).std()\n",
    "\n",
    "    # --- On-Balance Volume (OBV) ---\n",
    "    OBV =  ta.volume.OnBalanceVolumeIndicator(df_loc['prev_close'], df_loc['prev_Volume']).on_balance_volume() \n",
    "    df_loc['OBV_zscore'] = (OBV - OBV.rolling(20).mean()) / OBV.rolling(20).std()\n",
    "    df_loc['OBV_pct_change'] = OBV.pct_change()\n",
    "\n",
    "    # --- Chaikin Money Flow (CMF) ---\n",
    "    CMF = ta.volume.ChaikinMoneyFlowIndicator(df_loc['prev_high'], df_loc['prev_low'], df_loc['prev_close'], df_loc['prev_Volume']).chaikin_money_flow()\n",
    "    df_loc['CMF_zscore'] = (CMF - CMF.rolling(20).mean()) / CMF.rolling(20).std()\n",
    "\n",
    "    # --- RSI ---\n",
    "    df_loc['rsi_14'] = ta.momentum.RSIIndicator(close=df_loc['prev_close'], window=14).rsi()\n",
    "\n",
    "    # --- EMA Ratio ---\n",
    "    df_loc['ema_10'] = df_loc['prev_close'] / ta.trend.EMAIndicator(close=df_loc['prev_close'], window=10).ema_indicator()\n",
    "\n",
    "    # --- Moving Average Slope ---\n",
    "    ma_10 = df_loc['prev_close'].rolling(window=10).mean()\n",
    "    df_loc['slope_ma_10'] = ma_10.diff() / ma_10\n",
    "\n",
    "    # --- Bollinger Bands ---\n",
    "    bollinger = ta.volatility.BollingerBands(df_loc['prev_close'])\n",
    "    df_loc['close_to_upper_band'] = df_loc['prev_close'] / bollinger.bollinger_hband()\n",
    "    df_loc['close_to_lower_band'] = df_loc['prev_close'] / bollinger.bollinger_lband()\n",
    "\n",
    "    # --- Volume Z-Score ---\n",
    "    df_loc['volume_zscore_20'] = (df_loc['prev_Volume'] - df_loc['prev_Volume'].rolling(20).mean()) / df_loc['prev_Volume'].rolling(20).std()\n",
    "\n",
    "    # --- Time Features ---\n",
    "    df_loc['hour'] = pd.to_datetime(df_loc['time']).dt.hour\n",
    "    df_loc['weekday'] = pd.to_datetime(df_loc['time']).dt.weekday\n",
    "\n",
    "    # --- Finalize: Drop columns and reset index ---\n",
    "    df_loc = df_loc.dropna().reset_index(drop=True)\n",
    "    drop_cols = ['prev_open', 'prev_close', 'prev_high', 'prev_low', 'prev_Volume', 'trade_result', 'trade_id']\n",
    "    return df_loc.drop(drop_cols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0996129",
   "metadata": {},
   "source": [
    "## 5. Lagged Feature Generation\n",
    "\n",
    "Creates lagged features for time series modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd4c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lag_features(df_loc):\n",
    "    \"\"\"\n",
    "    Generate lagged features for time series modeling.\n",
    "\n",
    "    Parameters:\n",
    "        df_loc (pd.DataFrame): Input DataFrame with features.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with lagged features for past 2 rows (lag1, lag2).\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df_lagged = df_loc.copy()\n",
    "\n",
    "    # Select columns to lag (exclude non-feature columns)\n",
    "    exclude_cols = ['time', 'label', 'stock_id', 'open', 'supertrend']\n",
    "    columns_to_lag = [col for col in df_lagged.columns if col not in exclude_cols]\n",
    "\n",
    "    # Create lag features for past 2 rows (lag1, lag2)\n",
    "    for lag in range(1, 3):\n",
    "        # Shift selected columns by 'lag' periods\n",
    "        lagged_cols = df_lagged[columns_to_lag].shift(lag)\n",
    "        # Rename columns to indicate lag\n",
    "        lagged_cols.columns = [f\"{col}_lag{lag}\" for col in lagged_cols.columns]\n",
    "        # Concatenate lagged columns to the DataFrame\n",
    "        df_lagged = pd.concat([df_lagged, lagged_cols], axis=1)\n",
    "\n",
    "    # Drop rows with NaN values introduced by lagging and reset index\n",
    "    return df_lagged.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb215005",
   "metadata": {},
   "source": [
    "## 6. Sentiment Feature Integration\n",
    "\n",
    "Preprocess and merges news & Twitter sentiment features into the main stock DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_data(stock, df):\n",
    "    \"\"\"\n",
    "    Merge news sentiment features into the main stock DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        stock (str): Stock ticker symbol.\n",
    "        df (pd.DataFrame): Main DataFrame containing stock data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with news sentiment features merged.\n",
    "    \"\"\"\n",
    "    # Load news data for the given stock\n",
    "    news_df = pd.read_csv(f'data/news/{stock}.csv')\n",
    "\n",
    "    # Convert 'Date' column to datetime\n",
    "    news_df['Date'] = pd.to_datetime(news_df['Date'], format='mixed', errors='coerce')\n",
    "\n",
    "    # Select relevant columns and rename for clarity\n",
    "    news_df = news_df[['Date', 'News Publication Count (L1)', 'News Positive Sentiment Count', 'News Negative Sentiment Count']]\n",
    "    news_df = news_df.rename(columns={\n",
    "        'News Publication Count (L1)': 'news_count',\n",
    "        'News Positive Sentiment Count': 'news_pos',\n",
    "        'News Negative Sentiment Count': 'news_neg'\n",
    "    })\n",
    "\n",
    "    # Fill missing values with zero\n",
    "    news_df[['news_count', 'news_pos', 'news_neg']] = news_df[['news_count', 'news_pos', 'news_neg']].fillna(0)\n",
    "\n",
    "    # Boost sentiment counts \n",
    "    news_df['news_neg'] = np.where(news_df['news_neg'] < 0, news_df['news_neg'] - 5, 0)\n",
    "    news_df['news_pos'] = np.where(news_df['news_pos'] > 0, news_df['news_pos'] + 5, 0)\n",
    "\n",
    "    # Calculate total sentiment and invert negative sentiment for feature engineering\n",
    "    news_df['news_total'] = news_df['news_neg'] + news_df['news_pos']\n",
    "    news_df['news_neg'] = news_df['news_neg'].abs()\n",
    "\n",
    "    # Create lagged features (previous day's values)\n",
    "    prev_news_neg = news_df['news_neg'].shift(1)\n",
    "    prev_news_pos = news_df['news_pos'].shift(1)\n",
    "    prev_news_total = news_df['news_total'].shift(1)\n",
    "    prev_news_count = news_df['news_count'].shift(1)\n",
    "\n",
    "    # Rolling averages (5-day window)\n",
    "    news_df['news_pos_avg5'] = prev_news_pos.rolling(window=5).mean()\n",
    "    news_df['news_neg_avg5'] = prev_news_neg.rolling(window=5).mean()\n",
    "    news_df['news_total_avg5'] = prev_news_total.rolling(window=5).mean()\n",
    "    news_df['news_count_avg5'] = prev_news_count.rolling(window=5).mean()\n",
    "\n",
    "    # Daily changes in sentiment features\n",
    "    news_df['news_pos_change'] = prev_news_pos.diff()\n",
    "    news_df['news_neg_change'] = prev_news_neg.diff()\n",
    "    news_df['news_total_change'] = prev_news_total.diff()\n",
    "    news_df['news_count_change'] = prev_news_count.diff()\n",
    "\n",
    "    # Drop intermediate columns to keep only engineered features\n",
    "    news_df = news_df.drop(['news_neg', 'news_pos', 'news_total', 'news_count'], axis=1, errors='ignore')\n",
    "\n",
    "    # Extract date for merging\n",
    "    news_df['date_only'] = news_df['Date'].dt.date\n",
    "\n",
    "    # Merge news features into main DataFrame on date\n",
    "    df = df.merge(news_df.drop(columns='Date'), on='date_only', how='left')\n",
    "\n",
    "    # Fill missing engineered features with zero\n",
    "    feature_cols = [\n",
    "        'news_count_avg5', 'news_pos_avg5', 'news_neg_avg5', 'news_total_avg5',\n",
    "        'news_count_change', 'news_pos_change', 'news_neg_change', 'news_total_change'\n",
    "    ]\n",
    "    df[feature_cols] = df[feature_cols].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_twitter_data(stock, df):\n",
    "    \"\"\"\n",
    "    Merge engineered Twitter sentiment features into the main stock DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        stock (str): Stock ticker symbol.\n",
    "        df (pd.DataFrame): Main DataFrame containing stock data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with Twitter sentiment features merged.\n",
    "    \"\"\"\n",
    "    # Load Twitter sentiment data for the given stock\n",
    "    twitter_df = pd.read_csv(f'data/twitter/{stock}.csv')\n",
    "\n",
    "    # Convert 'Date' column to datetime (mixed format, handle errors)\n",
    "    twitter_df['Date'] = pd.to_datetime(twitter_df['Date'], format='mixed', errors='coerce')\n",
    "\n",
    "    # Select relevant columns and rename for clarity\n",
    "    twitter_df = twitter_df[['Date', 'Twitter Publication Count (L1)', 'Twitter Positive Sentiment Count', 'Twitter Negative Sentiment Count']]\n",
    "    twitter_df = twitter_df.rename(columns={\n",
    "        'Twitter Publication Count (L1)': 'twitter_count',\n",
    "        'Twitter Positive Sentiment Count': 'twitter_pos',\n",
    "        'Twitter Negative Sentiment Count': 'twitter_neg'\n",
    "    })\n",
    "\n",
    "    # Fill missing values with zero\n",
    "    twitter_df[['twitter_count', 'twitter_pos', 'twitter_neg']] = twitter_df[['twitter_count', 'twitter_pos', 'twitter_neg']].fillna(0)\n",
    "\n",
    "    # Boost sentiment counts \n",
    "    twitter_df['twitter_neg'] = np.where(twitter_df['twitter_neg'] < 0, twitter_df['twitter_neg'] - 5, 0)\n",
    "    twitter_df['twitter_pos'] = np.where(twitter_df['twitter_pos'] > 0, twitter_df['twitter_pos'] + 5, 0)\n",
    "\n",
    "    # Calculate total sentiment and invert negative sentiment for feature engineering\n",
    "    twitter_df['twitter_total'] = twitter_df['twitter_neg'] + twitter_df['twitter_pos']\n",
    "    twitter_df['twitter_neg'] = twitter_df['twitter_neg'].abs()\n",
    "\n",
    "    # Create lagged features (previous day's values)\n",
    "    prev_twitter_neg = twitter_df['twitter_neg'].shift(1)\n",
    "    prev_twitter_pos = twitter_df['twitter_pos'].shift(1)\n",
    "    prev_twitter_total = twitter_df['twitter_total'].shift(1)\n",
    "    prev_twitter_count = twitter_df['twitter_count'].shift(1)\n",
    "\n",
    "    # Rolling averages (5-day window)\n",
    "    twitter_df['twitter_pos_avg5'] = prev_twitter_pos.rolling(window=5).mean()\n",
    "    twitter_df['twitter_neg_avg5'] = prev_twitter_neg.rolling(window=5).mean()\n",
    "    twitter_df['twitter_total_avg5'] = prev_twitter_total.rolling(window=5).mean()\n",
    "    twitter_df['twitter_count_avg5'] = prev_twitter_count.rolling(window=5).mean()\n",
    "\n",
    "    # Daily changes in sentiment features\n",
    "    twitter_df['twitter_pos_change'] = prev_twitter_pos.diff()\n",
    "    twitter_df['twitter_neg_change'] = prev_twitter_neg.diff()\n",
    "    twitter_df['twitter_total_change'] = prev_twitter_total.diff()\n",
    "    twitter_df['twitter_count_change'] = prev_twitter_count.diff()\n",
    "\n",
    "    # Drop intermediate columns to keep only engineered features\n",
    "    twitter_df = twitter_df.drop(['twitter_neg', 'twitter_pos', 'twitter_total', 'twitter_count'], axis=1, errors='ignore')\n",
    "\n",
    "    # Extract date for merging\n",
    "    twitter_df['date_only'] = twitter_df['Date'].dt.date\n",
    "\n",
    "    # Merge Twitter features into main DataFrame on date\n",
    "    df = df.merge(twitter_df.drop(columns='Date'), on='date_only', how='left')\n",
    "\n",
    "    # Fill missing engineered features with zero\n",
    "    feature_cols = [\n",
    "        'twitter_count_avg5', 'twitter_pos_avg5', 'twitter_neg_avg5', 'twitter_total_avg5',\n",
    "        'twitter_count_change', 'twitter_pos_change', 'twitter_neg_change', 'twitter_total_change'\n",
    "    ]\n",
    "    df[feature_cols] = df[feature_cols].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15d734",
   "metadata": {},
   "source": [
    "## 7. Stock Selection by Sentiment Activity\n",
    "\n",
    "Selects top stocks based on combined news and Twitter publication counts for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6257c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select top stocks by combined news & twitter publication count ---\n",
    "\n",
    "# Get all news CSV files\n",
    "news_files = glob.glob(\"data/news/*.csv\")\n",
    "\n",
    "score_list = []\n",
    "\n",
    "# Loop through each stock's news file\n",
    "for file in news_files:\n",
    "    stock_id = os.path.basename(file).replace(\".csv\", \"\")\n",
    "    \n",
    "    # Load news data and filter for years >= 2016\n",
    "    news_df = pd.read_csv(file)\n",
    "    news_df['Date'] = pd.to_datetime(news_df['Date'], format='mixed', errors='coerce')\n",
    "    news_df = news_df[news_df['Date'].dt.year >= 2016]\n",
    "    mean_news = news_df['News Publication Count (L1)'].mean()\n",
    "    \n",
    "    # Load corresponding twitter data and filter for years >= 2016\n",
    "    twitter_df = pd.read_csv(f'data/twitter/{stock_id}.csv')\n",
    "    twitter_df['Date'] = pd.to_datetime(twitter_df['Date'], format='mixed', errors='coerce')\n",
    "    twitter_df = twitter_df[twitter_df['Date'].dt.year >= 2016]\n",
    "    mean_twitter = twitter_df['Twitter Publication Count (L1)'].mean()\n",
    "    \n",
    "    # Calculate combined score (product of means)\n",
    "    score = mean_news * mean_twitter\n",
    "    score_list.append((stock_id, score))\n",
    "\n",
    "# Sort stocks by score (descending)\n",
    "score_list_sorted = sorted(score_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print sorted results and select top 32 stocks \n",
    "score_df = pd.DataFrame(score_list_sorted, columns=['Stock ID', 'Score'])\n",
    "pd.set_option('display.float_format', '{:,.0f}'.format)\n",
    "\n",
    "# Display the table\n",
    "print(\"Top Stocks by Combined News & Twitter Publication Count:\")\n",
    "print(score_df.to_string(index=True))\n",
    "\n",
    "# Select top 32 stocks\n",
    "sentiment_top_list = score_df['Stock ID'].head(32).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96155219",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Stocks count: \", len(score_list_sorted))\n",
    "print(\"Total Selected Stocks count: \", len(sentiment_top_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84050208",
   "metadata": {},
   "source": [
    "## 8. Data Loading & Preprocessing\n",
    "\n",
    "Loads OHLCV, macro indices, and merges sentiment features. Prepares data for feature engineering and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9027ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load and process stock data for ML modeling ===\n",
    "\n",
    "# 1. Gather all stock OHLCV files \n",
    "stock_files = glob.glob(\"data/OHLCV/*.csv\")\n",
    "\n",
    "all_data = []  # List to collect processed DataFrames\n",
    "count = 0      # Counter for progress tracking\n",
    "\n",
    "for file in stock_files:\n",
    "    stock_id = os.path.basename(file).replace(\".csv\", \"\")\n",
    "\n",
    "    # --- Load and process SPX index data ---\n",
    "    df_spx = pd.read_csv(\"data/SP_SPX.csv\")\n",
    "    df_spx['time'] = pd.to_datetime(df_spx['time'], unit='s')\n",
    "    df_spx['spx_return'] = df_spx['close'].pct_change()\n",
    "    ma_6_spx = df_spx['close'].rolling(window=6).mean()\n",
    "    df_spx['slope_ma_6_spx'] = ma_6_spx.diff() / ma_6_spx\n",
    "    df_spx['spx_return'] = df_spx['spx_return'].shift(1)\n",
    "    df_spx['slope_ma_6_spx'] = df_spx['slope_ma_6_spx'].shift(1)\n",
    "    df_spx = df_spx[['time', 'spx_return', 'slope_ma_6_spx']]\n",
    "\n",
    "    # --- Load and process VIX index data ---\n",
    "    df_vix = pd.read_csv(\"data/VIX_1h.csv\")\n",
    "    df_vix['time'] = pd.to_datetime(df_vix['time'], unit='s')\n",
    "    df_vix = df_vix.rename(columns={'close': 'vix_close'})\n",
    "    ma_6_vix = df_vix['vix_close'].rolling(window=6).mean()\n",
    "    df_vix['slope_ma_6_vix'] = ma_6_vix.diff() / ma_6_vix\n",
    "    df_vix['vix_close'] = df_vix['vix_close'].shift(1)\n",
    "    df_vix['slope_ma_6_vix'] = df_vix['slope_ma_6_vix'].shift(1)\n",
    "    df_vix = df_vix[['time', 'vix_close', 'slope_ma_6_vix']]\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    # --- Only process stocks in the sentiment top list ---\n",
    "    if stock_id in sentiment_top_list:\n",
    "        # Load stock OHLCV data\n",
    "        df = pd.read_csv(file)\n",
    "        df['stock_id'] = stock_id\n",
    "        # print(count, stock_id)\n",
    "\n",
    "        # --- Prepare time and sort ---\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "        df = df.sort_values(['time']).reset_index(drop=True)\n",
    "\n",
    "        # --- Create shifted OHLCV features for technical analysis ---\n",
    "        df['prev_close'] = df['open']\n",
    "        df['prev_high'] = df['high'].shift(1)\n",
    "        df['prev_open'] = df['open'].shift(1)\n",
    "        df['prev_low'] = df['low'].shift(1)\n",
    "        df['prev_Volume'] = df['Volume'].shift(1)\n",
    "\n",
    "        # --- Ensure previous high/low are not extreme compared to open ---\n",
    "        df['prev_high'] = np.where(df['prev_high'] < df['prev_close'], df['prev_close'], df['prev_high'])\n",
    "        df['prev_low'] = np.where(df['prev_low'] > df['prev_close'], df['prev_close'], df['prev_low'])\n",
    "\n",
    "        # --- Drop unused columns ---\n",
    "        df = df.drop(['close', 'high', 'low', 'Volume'], axis=1, errors='ignore')\n",
    "\n",
    "        # --- Merge macro indices (SPX, VIX) ---\n",
    "        df = df.merge(df_spx, on='time', how='left')\n",
    "        df = pd.merge_asof(df, df_vix, on='time', direction='backward')\n",
    "        df['vix_close'] = df['vix_close'].ffill()\n",
    "        df['slope_ma_6_vix'] = df['slope_ma_6_vix'].ffill()\n",
    "\n",
    "        # --- Filter for recent years ---\n",
    "        df = df[df['time'].dt.year >= 2016]\n",
    "\n",
    "        # --- Add date column for sentiment merge ---\n",
    "        df['date_only'] = df['time'].dt.date\n",
    "\n",
    "        # --- Merge news and twitter sentiment features ---\n",
    "        df = get_news_data(stock_id, df)\n",
    "        df = get_twitter_data(stock_id, df)\n",
    "\n",
    "        # --- Calculate Supertrend indicator and trade IDs ---\n",
    "        df = calculate_supertrend(df)\n",
    "\n",
    "        # --- Map next open price for each trade group ---\n",
    "        future_opens = df.groupby('trade_id')['open'].first().shift(-1)\n",
    "        future_open_map = future_opens.to_dict()\n",
    "        df['next_open'] = df['trade_id'].map(future_open_map)\n",
    "\n",
    "        # --- Assign trade result labels ---\n",
    "        df = df.groupby('trade_id', group_keys=False).apply(evaluate_trade, include_groups=False)\n",
    "\n",
    "        # --- Clean up helper columns ---\n",
    "        df = df.drop(['next_open', 'date_only'], axis=1, errors='ignore')\n",
    "\n",
    "        # --- Assign ML label column ---\n",
    "        df['label'] = df['trade_result']\n",
    "\n",
    "        # --- Drop rows with missing values ---\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        # --- Feature engineering for ML ---\n",
    "        df = generate_features(df)\n",
    "\n",
    "        # --- Add lagged features ---\n",
    "        df = generate_lag_features(df)\n",
    "\n",
    "        # --- Collect processed DataFrame ---\n",
    "        all_data.append(df)\n",
    "\n",
    "# --- Concatenate all processed stock data ---\n",
    "df_all = pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e407c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55740cc",
   "metadata": {},
   "source": [
    "## 9. Machine Learning Pipeline\n",
    "\n",
    "Trains a LightGBM classifier using engineered features. Evaluates model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31701469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ML Model Training & Evaluation Pipeline ---\n",
    "\n",
    "# 1. Identify Supertrend change points (potential trade signals)\n",
    "supertrend_change_mask = df_all['supertrend'] != df_all['supertrend'].shift(1)\n",
    "\n",
    "# 2. Filter only rows where Supertrend changes (entry/exit points)\n",
    "df_supertrend_changes = df_all[supertrend_change_mask].copy()\n",
    "df_supertrend_changes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 3. Time-based Train/Test split (train: <2023, test: >=2023)\n",
    "df_train = df_supertrend_changes[df_supertrend_changes['time'].dt.year < 2023]\n",
    "df_test = df_supertrend_changes[df_supertrend_changes['time'].dt.year >= 2023].copy()\n",
    "df_all_test = df_all[df_all['time'].dt.year >= 2023]\n",
    "\n",
    "# 4. Prepare features and labels for ML\n",
    "X_train = df_train.drop(['time', 'label', 'stock_id', 'open'], axis=1, errors='ignore')\n",
    "y_train = df_train['label']\n",
    "\n",
    "X_test = df_test.drop(['time', 'label', 'stock_id', 'open'], axis=1, errors='ignore')\n",
    "y_test = df_test['label']\n",
    "\n",
    "class_names = ['Short (0)', 'Neutral (1)', 'Long (2)']\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"labels distribution:\\n\", df_supertrend_changes['label'].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 5. Initialize and configure LightGBM Classifier\n",
    "model_lgbm = LGBMClassifier(\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.01,\n",
    "    random_state=42,\n",
    "    max_depth=5,\n",
    "    num_leaves=24,\n",
    "    colsample_bytree=0.7,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1,\n",
    "    min_child_samples=19,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# 6. Train the model\n",
    "model_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# 7. Predict on test set and evaluate performance\n",
    "y_pred_lgbm = model_lgbm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_lgbm))\n",
    "\n",
    "# 8. Plot confusion matrix for classification results\n",
    "cm = confusion_matrix(y_test, y_pred_lgbm)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. Store predictions in test DataFrame for further analysis\n",
    "df_test.loc[:, 'predicted_label'] = y_pred_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a5e3a",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis\n",
    "\n",
    "Displays and visualizes the most important features for the LightGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9aecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Importance Visualization for LightGBM Model ---\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': model_lgbm.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the top 50 most important features\n",
    "print(feature_importance_df.head(50))  # Display top 50 features\n",
    "\n",
    "# Plot the top 50 feature importances as a horizontal bar chart\n",
    "plt.figure(figsize=(6, 10))\n",
    "plt.barh(\n",
    "    feature_importance_df['Feature'][:50][::-1],  # Reverse for descending order\n",
    "    feature_importance_df['Importance'][:50][::-1]\n",
    ")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top 50 Feature Importances\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dde8d0",
   "metadata": {},
   "source": [
    "## 11. ML Prediction Integration\n",
    "\n",
    "Merges ML predictions into the full test set and forward-fills missing signals for continuous simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge ML predictions into full test set and forward-fill missing signals ---\n",
    "\n",
    "# Merge predicted labels from ML test set into the full test DataFrame.\n",
    "df_final_display = df_all_test.merge(\n",
    "    df_test[['time', 'predicted_label', 'stock_id']],\n",
    "    on=['time', 'stock_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_final_display.loc[0, \"predicted_label\"] = 1  # Default to 'Neutral' for first row.\n",
    "\n",
    "# Forward-fill missing predicted labels so every row has a signal.\n",
    "df_final_display['predicted_label'] = df_final_display['predicted_label'].ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb962f6",
   "metadata": {},
   "source": [
    "## 12. Signal Visualization\n",
    "\n",
    "Plots open prices with Supertrend, true labels, and ML-predicted signals for selected stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef25366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization of ML and Supertrend signals for each stock ---\n",
    "\n",
    "max_num_stocks = 1 # change this to plot charts for more stocks\n",
    "\n",
    "num_stocks = 0\n",
    "\n",
    "# Group the full test set by stock_id for plotting\n",
    "for stock_id, df_plot in df_final_display.groupby('stock_id'):\n",
    "    \n",
    "    # Limit to first 3 stocks for visualization\n",
    "    if num_stocks < max_num_stocks:\n",
    "        print(f\"Plotting for stock_id: {stock_id}\")\n",
    "\n",
    "        # Reset index for clean plotting\n",
    "        df_plot = df_plot.reset_index(drop=True)\n",
    "\n",
    "        # Extract relevant columns for plotting\n",
    "        open_prices = df_plot['open']\n",
    "        predicted_labels = df_plot['predicted_label']\n",
    "        supertrend_test = df_plot['supertrend']\n",
    "        trade_result_test = df_plot['label']\n",
    "        time_plot = df_plot['time']\n",
    "\n",
    "        # --- Plot 1: Supertrend Buy/Sell Signals ---\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        plt.plot(time_plot, open_prices, label='Open Price', color='black')\n",
    "\n",
    "        # Identify buy/sell signals from Supertrend\n",
    "        buy_signals = df_plot[supertrend_test == 1].index\n",
    "        sell_signals = df_plot[supertrend_test == -1].index\n",
    "\n",
    "        plt.scatter(time_plot.iloc[buy_signals], open_prices.iloc[buy_signals], marker='o', color='green', label='Supertrend Buy', s=30)\n",
    "        plt.scatter(time_plot.iloc[sell_signals], open_prices.iloc[sell_signals], marker='o', color='red', label='Supertrend Sell', s=30)\n",
    "\n",
    "        plt.title(f\"Stock {stock_id} - Base Indicator Signals\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- Plot 2: True Trade Result Labels ---\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        plt.plot(time_plot, open_prices, label='Open Price', color='black')\n",
    "\n",
    "        # Identify buy/sell signals from true labels\n",
    "        buy_signals = df_plot[(trade_result_test == 2)].index\n",
    "        sell_signals = df_plot[(trade_result_test == 0)].index\n",
    "\n",
    "        plt.scatter(time_plot.iloc[buy_signals], open_prices.iloc[buy_signals], marker='o', color='green', label='Label Buy', s=30)\n",
    "        plt.scatter(time_plot.iloc[sell_signals], open_prices.iloc[sell_signals], marker='o', color='red', label='Label Sell', s=30)\n",
    "\n",
    "        plt.title(f\"Stock {stock_id} - Open Price with Labels\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- Plot 3: ML Predicted Buy/Sell Signals ---\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        plt.plot(time_plot, open_prices, label='Open Price', color='black')\n",
    "\n",
    "        # Identify buy/sell signals from ML predictions\n",
    "        buy_signals = df_plot[(predicted_labels == 2)].index\n",
    "        sell_signals = df_plot[(predicted_labels == 0)].index\n",
    "\n",
    "        plt.scatter(time_plot.iloc[buy_signals], open_prices.iloc[buy_signals], marker='o', color='green', label='Predicted Buy', s=40)\n",
    "        plt.scatter(time_plot.iloc[sell_signals], open_prices.iloc[sell_signals], marker='o', color='red', label='Predicted Sell', s=40)\n",
    "\n",
    "        plt.title(f\"Stock {stock_id} - Open Price with Predicted Signals\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    num_stocks += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31593d9",
   "metadata": {},
   "source": [
    "## 13. Portfolio Simulation with ML Model\n",
    "\n",
    "Simulates trading using ML signals, calculates PnL, drawdown, Sharpe ratio, and visualizes results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4616693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Portfolio PnL Calculation with ML Model ---\n",
    "# This block simulates trading for each stock using ML signals (and optionally Supertrend).\n",
    "# It tracks trades, calculates PnL, drawdown, Sharpe ratio, and visualizes results.\n",
    "\n",
    "# --- Initialize summary variables ---\n",
    "total_count = 0                # Number of stocks processed\n",
    "pnl_all = 0                    # Total PnL across all stocks\n",
    "buyNhold_pnl_all = 0           # Total buy & hold PnL across all stocks\n",
    "num_charts = 0                 # Chart counter for plotting\n",
    "max_num_charts = 3             # max number of stock charts for plotting\n",
    "is_long_only = False           # If True, disables short trades\n",
    "total_trades = 0               # Total number of trades\n",
    "total_winning_trades = 0       # Total number of winning trades\n",
    "trading_fees = 0.05            # Trading fee (%)\n",
    "ordersize = 100                # Order size for each trade\n",
    "is_ml_only = True              # If True, use only ML signals (ignore Supertrend)\n",
    "max_drawdown_list = []         # List to store max drawdown per stock\n",
    "initial_capital = 100\n",
    "\n",
    "# --- Risk-free rate for Sharpe ratio ---\n",
    "risk_free_annual = 0.04\n",
    "risk_free_daily = risk_free_annual / 252\n",
    "\n",
    "stock_pnl_dfs = []             # List to store PnL DataFrames for each stock\n",
    "\n",
    "# --- Main loop: process each stock ---\n",
    "for stock_id, df_stock in df_final_display.groupby('stock_id'):\n",
    "    df_stock = df_stock.reset_index(drop=True)\n",
    "\n",
    "    # --- Trade tracking variables ---\n",
    "    position = None            # Current position: 'long', 'short', or None\n",
    "    entry_price = 0            # Entry price for current position\n",
    "    entry_price_pnl = 0        # Entry price for PnL calculation\n",
    "    positions = []             # List to log all trades\n",
    "\n",
    "    openPrice = 0              # First open price (for buy & hold)\n",
    "    closePrice = 0             # Last close price (for buy & hold)\n",
    "\n",
    "    total_count += 1\n",
    "\n",
    "    # --- Drawdown tracking ---\n",
    "    max_drawdown = 0\n",
    "    max_drawdown_time = 0\n",
    "    drawdown = 0\n",
    "\n",
    "    # --- PnL tracking ---\n",
    "    pnl = []                   # List of hourly PnL dicts\n",
    "    pnl_time = [df_stock['time'].iloc[0]]  # List of timestamps for PnL\n",
    "    last_pnl_price = 0         # Last price for PnL calculation\n",
    "    max_pnl = 0                # Maximum cumulative PnL\n",
    "    current_pnl = 0            # Current cumulative PnL\n",
    "\n",
    "    # --- Iterate through each row (time step) in the stock DataFrame ---\n",
    "    for i, row in df_stock.iterrows():\n",
    "        price = row['open']\n",
    "        supertrend = row['supertrend']\n",
    "        predicted_label = row['predicted_label']\n",
    "\n",
    "        # --- Set open price for buy & hold calculation ---\n",
    "        if openPrice == 0:\n",
    "            openPrice = price\n",
    "\n",
    "        closePrice = price\n",
    "        fee = 0\n",
    "        old_position = position\n",
    "\n",
    "        # --- Entry/Exit Logic ---\n",
    "        # --- Open Long ---\n",
    "        if predicted_label == 2 and (supertrend == 1 or is_ml_only):\n",
    "            if position is None:\n",
    "                position = 'long'\n",
    "                entry_price = price\n",
    "                positions.append({\n",
    "                    'stock': row['stock_id'],\n",
    "                    'time': row['time'],\n",
    "                    'type': 'long',\n",
    "                    'entry': price,\n",
    "                    'exit': None,\n",
    "                    'pnl': None\n",
    "                })\n",
    "    \n",
    "                last_pnl_price = entry_price\n",
    "\n",
    "            elif position == 'short':\n",
    "                exit_price = price\n",
    "                profit = (entry_price - exit_price) * ordersize / entry_price\n",
    "                fee = ordersize * trading_fees * 2 / 100\n",
    "                positions[-1]['exit'] = exit_price\n",
    "                positions[-1]['exit_time'] = row['time']\n",
    "                positions[-1]['pnl'] = profit - fee\n",
    "\n",
    "                position = 'long'\n",
    "                entry_price = price\n",
    "                positions.append({\n",
    "                    'stock': row['stock_id'],\n",
    "                    'time': row['time'],\n",
    "                    'type': 'long',\n",
    "                    'entry': price,\n",
    "                    'exit': None,\n",
    "                    'pnl': None\n",
    "                })\n",
    "    \n",
    "\n",
    "        # --- Open Short ---\n",
    "        elif predicted_label == 0 and (supertrend == -1 or is_ml_only):\n",
    "            if position is None and not is_long_only:\n",
    "                position = 'short'\n",
    "                entry_price = price\n",
    "                positions.append({\n",
    "                    'stock': row['stock_id'],\n",
    "                    'time': row['time'],\n",
    "                    'type': 'short',\n",
    "                    'entry': price,\n",
    "                    'exit': None,\n",
    "                    'pnl': None\n",
    "                })\n",
    "    \n",
    "                last_pnl_price = entry_price\n",
    "\n",
    "            elif position == 'long':\n",
    "                exit_price = price\n",
    "                profit = (exit_price - entry_price) * ordersize / entry_price\n",
    "                fee = ordersize * trading_fees * 2 / 100\n",
    "                positions[-1]['exit'] = exit_price\n",
    "                positions[-1]['exit_time'] = row['time']\n",
    "                positions[-1]['pnl'] = profit - fee\n",
    "\n",
    "                if not is_long_only:\n",
    "                    position = 'short'\n",
    "                    entry_price = price\n",
    "                    positions.append({\n",
    "                        'stock': row['stock_id'],\n",
    "                        'time': row['time'],\n",
    "                        'type': 'short',\n",
    "                        'entry': price,\n",
    "                        'exit': None,\n",
    "                        'pnl': None\n",
    "                    })\n",
    "                    maxPrice = 0\n",
    "                    minPrice = 0\n",
    "                else:\n",
    "                    position = None\n",
    "\n",
    "        # --- Close Long Position ---\n",
    "        elif position == 'long' and (predicted_label == 1 or predicted_label == 0 or (supertrend == -1 and not is_ml_only)):\n",
    "            exit_price = price\n",
    "            profit = (exit_price - entry_price) * ordersize / entry_price\n",
    "            fee = ordersize * trading_fees * 2 / 100\n",
    "            positions[-1]['exit'] = exit_price\n",
    "            positions[-1]['exit_time'] = row['time']\n",
    "            positions[-1]['pnl'] = profit - fee\n",
    "            position = None\n",
    "\n",
    "        # --- Close Short Position ---\n",
    "        elif position == 'short' and (predicted_label == 1 or predicted_label == 2 or (supertrend == 1 and not is_ml_only)):\n",
    "            exit_price = price\n",
    "            profit = (entry_price - exit_price) * ordersize / entry_price\n",
    "            fee = ordersize * trading_fees * 2 / 100\n",
    "            positions[-1]['exit'] = exit_price\n",
    "            positions[-1]['exit_time'] = row['time']\n",
    "            positions[-1]['pnl'] = profit - fee\n",
    "            position = None\n",
    "\n",
    "        # --- Hourly PnL Calculation ---\n",
    "        if old_position == 'long':\n",
    "            exit_price = price\n",
    "            entry_price_pnl = last_pnl_price or entry_price\n",
    "            profit = (exit_price - entry_price_pnl) * ordersize / entry_price_pnl\n",
    "            pnl.append({'time': row['time'], 'hourly_pnl': profit - fee})\n",
    "            last_pnl_price = exit_price\n",
    "            current_pnl += profit - fee\n",
    "\n",
    "            if current_pnl > max_pnl or max_pnl == 0:\n",
    "                max_pnl = current_pnl\n",
    "            if current_pnl < max_pnl:\n",
    "                drawdown = current_pnl - max_pnl\n",
    "                if drawdown < max_drawdown:\n",
    "                    max_drawdown = drawdown\n",
    "                    max_drawdown_time = row['time']\n",
    "\n",
    "        elif old_position == 'short':\n",
    "            exit_price = price\n",
    "            entry_price_pnl = last_pnl_price or entry_price\n",
    "            profit = (entry_price_pnl - exit_price) * ordersize / entry_price_pnl\n",
    "            pnl.append({'time': row['time'], 'hourly_pnl': profit - fee})\n",
    "            last_pnl_price = exit_price\n",
    "            current_pnl += profit - fee\n",
    "\n",
    "            if current_pnl > max_pnl or max_pnl == 0:\n",
    "                max_pnl = current_pnl\n",
    "            if current_pnl < max_pnl:\n",
    "                drawdown = current_pnl - max_pnl\n",
    "                if drawdown < max_drawdown:\n",
    "                    max_drawdown = drawdown\n",
    "                    max_drawdown_time = row['time']\n",
    "\n",
    "    # --- Final position close at end of data ---\n",
    "    if position == 'long':\n",
    "        exit_price = price\n",
    "        entry_price_pnl = last_pnl_price or entry_price\n",
    "        profit = (exit_price - entry_price_pnl) * ordersize / entry_price_pnl\n",
    "        fee = ordersize * trading_fees * 2 / 100\n",
    "        pnl.append({'time': row['time'], 'hourly_pnl': profit - fee})\n",
    "        last_pnl_price = exit_price\n",
    "\n",
    "        # Final trade close\n",
    "        profit = (exit_price - entry_price) * ordersize / entry_price\n",
    "        positions[-1]['exit'] = exit_price\n",
    "        positions[-1]['exit_time'] = row['time']\n",
    "        positions[-1]['pnl'] = profit - fee\n",
    "        position = None\n",
    "\n",
    "        if current_pnl + profit < max_pnl:\n",
    "            drawdown = current_pnl + profit - max_pnl\n",
    "            if drawdown < max_drawdown:\n",
    "                max_drawdown = drawdown\n",
    "                max_drawdown_time = row['time']\n",
    "\n",
    "    elif position == 'short':\n",
    "        exit_price = price\n",
    "        entry_price_pnl = last_pnl_price or entry_price\n",
    "        profit = (entry_price_pnl - exit_price) * ordersize / entry_price_pnl\n",
    "        fee = ordersize * trading_fees * 2 / 100\n",
    "        pnl.append({'time': row['time'], 'hourly_pnl': profit - fee})\n",
    "        last_pnl_price = exit_price\n",
    "\n",
    "        # Final trade close\n",
    "        profit = (entry_price - exit_price) * ordersize / entry_price\n",
    "        positions[-1]['exit'] = exit_price\n",
    "        positions[-1]['exit_time'] = row['time']\n",
    "        positions[-1]['pnl'] = profit - fee\n",
    "        position = None\n",
    "\n",
    "        if current_pnl + profit < max_pnl:\n",
    "            drawdown = current_pnl + profit - max_pnl\n",
    "            if drawdown < max_drawdown:\n",
    "                max_drawdown = drawdown\n",
    "                max_drawdown_time = row['time']\n",
    "\n",
    "    # --- Create DataFrames for trades and PnL ---\n",
    "    trades_df = pd.DataFrame(positions)\n",
    "    pnl_df = pd.DataFrame(pnl)\n",
    "\n",
    "    # --- Time conversion for plotting ---\n",
    "    pnl_df['time'] = pd.to_datetime(pnl_df['time'])\n",
    "    pnl_df.set_index('time', inplace=True)\n",
    "    pnl_df['time'] = pnl_df.index\n",
    "\n",
    "    stock_pnl_dfs.append(pnl_df)\n",
    "\n",
    "    # --- Return calculations ---\n",
    "    pnl_df['hourly_return'] = pnl_df['hourly_pnl'] / 100\n",
    "    pnl_df['gross_return'] = 1 + pnl_df['hourly_return']\n",
    "    total_return = pnl_df['gross_return'].prod() - 1\n",
    "\n",
    "    # --- Daily returns and Sharpe ratio ---\n",
    "    daily_returns = pnl_df['gross_return'].resample('1D').prod(min_count=1) - 1\n",
    "    excess_daily_returns = daily_returns - risk_free_daily\n",
    "    mean_daily = excess_daily_returns.mean()\n",
    "    std_daily = excess_daily_returns.std()\n",
    "    sharpe = mean_daily / std_daily\n",
    "    sharpe_annual = sharpe * np.sqrt(252)\n",
    "\n",
    "    # --- Summary statistics ---\n",
    "    total_pnl = pnl_df['hourly_pnl'].sum()\n",
    "    num_trades = len(positions)\n",
    "    avg_pnl = total_pnl / num_trades if num_trades > 0 else 0\n",
    "    buynhold = (closePrice - openPrice) * ordersize / openPrice\n",
    "\n",
    "    pnl_all += total_pnl\n",
    "    buyNhold_pnl_all += buynhold\n",
    "\n",
    "    winning_trades = trades_df[trades_df['pnl'] > 0]\n",
    "    total_winning_trades += len(winning_trades)\n",
    "    win_rate = (len(winning_trades) / num_trades) * 100 if num_trades > 0 else 0\n",
    "\n",
    "    # --- Print summary for each stock ---\n",
    "    print(f\"Stock: {stock_id}\")\n",
    "    print(f\"Total PnL: {total_pnl:.2f}\")\n",
    "    print(f\"Max Drawdown: {max_drawdown:.2f}\")\n",
    "    print(f\"Max Drawdown Date: {max_drawdown_time}\")\n",
    "    print(f\"Buy & Hold PnL: {buynhold:.2f}\")\n",
    "    print(f\"Win Rate: {win_rate:.2f}%\")\n",
    "    print(f\"Number of Trades: {num_trades}\")\n",
    "    print(\"Annualized Sharpe:\", round(sharpe_annual, 3))\n",
    "    print(f\"Total Fees: {(num_trades * 2 * ordersize * trading_fees / 100):.2f}\")\n",
    "    print(f\"Last Date: {df_stock['time'].iloc[-1]}\")\n",
    "    print('')\n",
    "\n",
    "    total_trades += num_trades\n",
    "    max_drawdown_list.append(max_drawdown)\n",
    "\n",
    "    # --- Visualization: plot price, trades, and cumulative PnL ---\n",
    "    if num_charts < max_num_charts:\n",
    "        cumulative_pnl = pnl_df['hourly_pnl'].cumsum()\n",
    "        positions_df = pd.DataFrame(positions)\n",
    "\n",
    "        # Extract entry/exit for long/short trades\n",
    "        long_entries = positions_df[positions_df['type'] == 'long']\n",
    "        long_exits = long_entries[long_entries['exit'].notna()]\n",
    "        short_entries = positions_df[positions_df['type'] == 'short']\n",
    "        short_exits = short_entries[short_entries['exit'].notna()]\n",
    "\n",
    "        fig, ax1 = plt.subplots(figsize=(12, 4))\n",
    "        ax1.set_title(f\"{stock_id} - Token Price & Cumulative PnL - ML model\")\n",
    "        ax1.plot(df_stock['time'], df_stock['open'], color='black', label='Price')\n",
    "        ax1.set_ylabel('Token Price', color='black')\n",
    "        ax1.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "        # Shade long/short position periods\n",
    "        for _, row in long_exits.iterrows():\n",
    "            ax1.axvspan(row['time'], row['exit_time'], color='green',\n",
    "                        alpha=0.4 if row['pnl'] > 0 else 0.1,\n",
    "                        label='Active Long Position' if _ == 0 else None)\n",
    "        for _, row in short_exits.iterrows():\n",
    "            ax1.axvspan(row['time'], row['exit_time'], color='red',\n",
    "                        alpha=0.4 if row['pnl'] > 0 else 0.1,\n",
    "                        label='Active Short Position' if _ == 0 else None)\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(pnl_df['time'], cumulative_pnl, color='blue', label='Cumulative PnL', drawstyle='steps-post')\n",
    "        ax2.set_ylabel('Cumulative PnL', color='blue')\n",
    "        ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "        # Plot trade entry/exit markers\n",
    "        ax1.scatter(long_entries['time'], long_entries['entry'], marker='^', color='green', label='Long Entry', s=40)\n",
    "        ax1.scatter(long_exits['exit_time'], long_exits['exit'], marker='v', color='red', label='Long Exit', s=40)\n",
    "        ax1.scatter(short_entries['time'], short_entries['entry'], marker='v', color='red', label='Short Entry', s=40)\n",
    "        ax1.scatter(short_exits['exit_time'], short_exits['exit'], marker='^', color='green', label='Short Exit', s=40)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    num_charts += 1\n",
    "    \n",
    "# --- Portfolio summary statistics ---\n",
    "total_win_rate = (total_winning_trades / total_trades) * 100 if total_trades > 0 else 0\n",
    "\n",
    "print(f\"Total PnL: {pnl_all:.2f}\")\n",
    "print(f\"Average PnL: {pnl_all / total_count:.2f}\")\n",
    "print(f\"Average Max Drawdown: {sum(max_drawdown_list) / len(max_drawdown_list):.2f}\")\n",
    "print(f\"Buy & Hold Average PnL: {buyNhold_pnl_all / total_count:.2f}\")\n",
    "print(f\"Total Trades: {total_trades}\")\n",
    "print(f\"Win Rate: {total_win_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d23330d",
   "metadata": {},
   "source": [
    "## 14. Portfolio Return Aggregation & Visualization (ML Model)\n",
    "\n",
    "Aggregates returns across all stocks, plots equity curve and drawdown, and summarizes portfolio statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Portfolio-Level PnL Aggregation and Performance Evaluation ---\n",
    "\n",
    "# Initialize list to hold hourly PnL series for each stock (in %)\n",
    "stock_returns = []\n",
    "\n",
    "# Extract and align hourly PnL for each stock\n",
    "for i, df in enumerate(stock_pnl_dfs):\n",
    "    df = df.copy()\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df.drop_duplicates(subset='time')  # Ensure unique timestamps\n",
    "    df.set_index('time', inplace=True)\n",
    "\n",
    "    df[f'pnl_stock_{i}'] = df['hourly_pnl']  # Already in %\n",
    "    stock_returns.append(df[[f'pnl_stock_{i}']])\n",
    "\n",
    "# Combine all stock PnL time series into one DataFrame\n",
    "portfolio_df = pd.concat(stock_returns, axis=1).fillna(0)\n",
    "\n",
    "# Compute equal-weighted portfolio hourly return (in %) \n",
    "portfolio_df['portfolio_hourly_return'] = portfolio_df.mean(axis=1) \n",
    "\n",
    "# Calculate cumulative PnL over time (in %) \n",
    "portfolio_df['cumulative_pnl_percent'] = portfolio_df['portfolio_hourly_return'].cumsum()\n",
    "\n",
    "# -- Calculate daily returns and Sharpe ratio --\n",
    "# Convert hourly returns to gross returns for compounding\n",
    "portfolio_df['gross_return'] = 1 + portfolio_df['portfolio_hourly_return'] / 100\n",
    "\n",
    "# Resample to daily gross returns and compute daily return\n",
    "daily_returns = portfolio_df['gross_return'].resample('1D').prod() - 1\n",
    "\n",
    "# Excess return over risk-free rate (daily)\n",
    "excess_daily_returns = daily_returns - risk_free_daily\n",
    "mean_excess = excess_daily_returns.mean()\n",
    "std_excess = excess_daily_returns.std()\n",
    "\n",
    "# Daily and annualized Sharpe ratio\n",
    "sharpe_daily = mean_excess / std_excess\n",
    "sharpe_annual = sharpe_daily * np.sqrt(252)\n",
    "\n",
    "# Compute drawdown from cumulative PnL \n",
    "# Start from 100 to simulate a normalized capital base\n",
    "cumulative = portfolio_df['cumulative_pnl_percent'] + 100\n",
    "rolling_max = cumulative.cummax()\n",
    "drawdown = (cumulative - rolling_max) / rolling_max\n",
    "portfolio_df['drawdown'] = drawdown\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
    "\n",
    "# Plot equity curve\n",
    "axes[0].plot(portfolio_df.index, portfolio_df['cumulative_pnl_percent'], color='blue', label='Cumulative PnL (%)')\n",
    "axes[0].set_title(\"Portfolio Cumulative PnL Over Time\")\n",
    "axes[0].set_ylabel(\"Cumulative PnL (%)\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot drawdown\n",
    "axes[1].plot(portfolio_df.index, portfolio_df['drawdown'] * 100, color='red', label='Drawdown (%)')\n",
    "axes[1].set_title(\"Portfolio Drawdown Over Time\")\n",
    "axes[1].set_xlabel(\"Time\")\n",
    "axes[1].set_ylabel(\"Drawdown (%)\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print performance summary \n",
    "final_pnl = portfolio_df['cumulative_pnl_percent'].iloc[-1]\n",
    "\n",
    "print(f\"Annualized Sharpe Ratio : {sharpe_annual:.3f}\")\n",
    "print(f\"Maximum Drawdown        : {max_drawdown * 100:.2f}%\")\n",
    "print(f\"Total Cumulative PnL    : {final_pnl:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47318c9d",
   "metadata": {},
   "source": [
    "## 15. Portfolio Simulation with Supertrend Indicator\n",
    "\n",
    "Simulates trading using only Supertrend signals, calculates PnL, drawdown, Sharpe ratio, and visualizes results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c0dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Portfolio PnL Calculation using Supertrend indicator only ---\n",
    "# This block simulates trading for each stock using only Supertrend signals.\n",
    "# It tracks trades, calculates PnL, drawdown, Sharpe ratio, and visualizes results.\n",
    "\n",
    "# === Initialize summary variables ===\n",
    "total_count = 0                # Number of stocks processed\n",
    "pnl_all = 0                    # Total PnL across all stocks\n",
    "buyNhold_pnl_all = 0           # Total buy & hold PnL across all stocks\n",
    "num_charts = 0                 # Chart counter for plotting\n",
    "max_num_charts = 3            # max number of stock charts for plotting\n",
    "is_long_only = False           # If True, disables short trades\n",
    "total_trades = 0               # Total number of trades\n",
    "total_winning_trades = 0       # Total number of winning trades\n",
    "trading_fees = 0.05            # Trading fee (%)\n",
    "ordersize = 100                # Order size for each trade\n",
    "max_drawdown_list = []         # List to store max drawdown per stock\n",
    "\n",
    "# === Risk-free rate for Sharpe ratio ===\n",
    "risk_free_annual = 0.04\n",
    "risk_free_daily = risk_free_annual / 252\n",
    "\n",
    "stock_pnl_dfs_2 = []             # List to store PnL DataFrames for each stock\n",
    "\n",
    "# === Main loop: process each stock ===\n",
    "for stock_id, df_stock in df_final_display.groupby('stock_id'):\n",
    "    df_stock = df_stock.reset_index(drop=True)\n",
    "\n",
    "    # --- Trade tracking variables ---\n",
    "    position = None            # Current position: 'long', 'short', or None\n",
    "    entry_price = 0            # Entry price for current position\n",
    "    entry_price_pnl = 0        # Entry price for PnL calculation\n",
    "    positions = []             # List to log all trades\n",
    "\n",
    "    openPrice = 0              # First open price (for buy & hold)\n",
    "    closePrice = 0             # Last close price (for buy & hold)\n",
    "\n",
    "    total_count += 1\n",
    "\n",
    "    # --- Drawdown tracking ---\n",
    "    max_drawdown = 0\n",
    "    max_drawdown_time = 0\n",
    "    drawdown = 0\n",
    "\n",
    "    # --- PnL tracking ---\n",
    "    pnl = []                   # List of hourly PnL dicts\n",
    "    pnl_time = [df_stock['time'].iloc[0]]  # List of timestamps for PnL\n",
    "    last_pnl_price = 0         # Last price for PnL calculation\n",
    "    max_pnl = 0                # Maximum cumulative PnL\n",
    "    current_pnl = 0            # Current cumulative PnL\n",
    "\n",
    "\n",
    "    # --- Iterate through each row (time step) in the stock DataFrame ---\n",
    "    for i, row in df_stock.iterrows():\n",
    "        price = row['open']\n",
    "        supertrend = row['supertrend']\n",
    "        predicted_label = row['predicted_label']\n",
    "\n",
    "        # --- Set open price for buy & hold calculation ---\n",
    "        if openPrice == 0:\n",
    "            openPrice = price\n",
    "\n",
    "        closePrice = price\n",
    "        fee = 0\n",
    "        old_position = position\n",
    "\n",
    "        # --- Entry/Exit Logic ---\n",
    "        # --- Open Long ---\n",
    "        if supertrend == 1:\n",
    "            if position is None:\n",
    "                position = 'long'\n",
    "                entry_price = price\n",
    "                positions.append({\n",
    "                    'stock': row['stock_id'],\n",
    "                    'time': row['time'],\n",
    "                    'type': 'long',\n",
    "                    'entry': price,\n",
    "                    'exit': None,\n",
    "                    'pnl': None\n",
    "                })\n",
    "                last_pnl_price = entry_price\n",
    "\n",
    "            elif position == 'short':\n",
    "                exit_price = price\n",
    "                profit = (entry_price - exit_price) * ordersize / entry_price\n",
    "                fee = ordersize * trading_fees * 2 / 100\n",
    "                positions[-1]['exit'] = exit_price\n",
    "                positions[-1]['exit_time'] = row['time']\n",
    "                positions[-1]['pnl'] = profit - fee\n",
    "\n",
    "                position = 'long'\n",
    "                entry_price = price\n",
    "                positions.append({\n",
    "                    'stock': row['stock_id'],\n",
    "                    'time': row['time'],\n",
    "                    'type': 'long',\n",
    "                    'entry': price,\n",
    "                    'exit': None,\n",
    "                    'pnl': None\n",
    "                })\n",
    "\n",
    "        # --- Open Short ---\n",
    "        elif supertrend == -1:\n",
    "            if position is None and not is_long_only:\n",
    "                position = 'short'\n",
    "                entry_price = price\n",
    "                positions.append({\n",
    "                    'stock': row['stock_id'],\n",
    "                    'time': row['time'],\n",
    "                    'type': 'short',\n",
    "                    'entry': price,\n",
    "                    'exit': None,\n",
    "                    'pnl': None\n",
    "                })\n",
    "                last_pnl_price = entry_price\n",
    "\n",
    "            elif position == 'long':\n",
    "                exit_price = price\n",
    "                profit = (exit_price - entry_price) * ordersize / entry_price\n",
    "                fee = ordersize * trading_fees * 2 / 100\n",
    "                positions[-1]['exit'] = exit_price\n",
    "                positions[-1]['exit_time'] = row['time']\n",
    "                positions[-1]['pnl'] = profit - fee\n",
    "\n",
    "                if not is_long_only:\n",
    "                    position = 'short'\n",
    "                    entry_price = price\n",
    "                    positions.append({\n",
    "                        'stock': row['stock_id'],\n",
    "                        'time': row['time'],\n",
    "                        'type': 'short',\n",
    "                        'entry': price,\n",
    "                        'exit': None,\n",
    "                        'pnl': None\n",
    "                    })\n",
    "                    maxPrice = 0\n",
    "                    minPrice = 0\n",
    "                else:\n",
    "                    position = None\n",
    "\n",
    "        # --- Hourly PnL Calculation ---\n",
    "        if old_position == 'long':\n",
    "            exit_price = price\n",
    "            entry_price_pnl = last_pnl_price or entry_price\n",
    "            profit = (exit_price - entry_price_pnl) * ordersize / entry_price_pnl\n",
    "            pnl.append({'time': row['time'], 'hourly_pnl': profit - fee})\n",
    "            last_pnl_price = exit_price\n",
    "            current_pnl += profit - fee\n",
    "\n",
    "            if current_pnl > max_pnl or max_pnl == 0:\n",
    "                max_pnl = current_pnl\n",
    "            if current_pnl < max_pnl:\n",
    "                drawdown = current_pnl - max_pnl\n",
    "                if drawdown < max_drawdown:\n",
    "                    max_drawdown = drawdown\n",
    "                    max_drawdown_time = row['time']\n",
    "\n",
    "        elif old_position == 'short':\n",
    "            exit_price = price\n",
    "            entry_price_pnl = last_pnl_price or entry_price\n",
    "            profit = (entry_price_pnl - exit_price) * ordersize / entry_price_pnl\n",
    "            pnl.append({'time': row['time'], 'hourly_pnl': profit - fee})\n",
    "            last_pnl_price = exit_price\n",
    "            current_pnl += profit - fee\n",
    "\n",
    "            if current_pnl > max_pnl or max_pnl == 0:\n",
    "                max_pnl = current_pnl\n",
    "            if current_pnl < max_pnl:\n",
    "                drawdown = current_pnl - max_pnl\n",
    "                if drawdown < max_drawdown:\n",
    "                    max_drawdown = drawdown\n",
    "                    max_drawdown_time = row['time']\n",
    "\n",
    "    # --- Final position close at end of data ---\n",
    "    if position == 'long':\n",
    "        exit_price = price\n",
    "        entry_price_pnl = last_pnl_price or entry_price\n",
    "        profit = (exit_price - entry_price_pnl) * ordersize / entry_price_pnl\n",
    "        fee = ordersize * trading_fees * 2 / 100\n",
    "        pnl.append({'time': row['time'], 'hourly_pnl': profit - fee})\n",
    "        last_pnl_price = exit_price\n",
    "\n",
    "        # --- Close open position for summary stats ---\n",
    "        profit = (exit_price - entry_price) * ordersize / entry_price\n",
    "        positions[-1]['exit'] = exit_price\n",
    "        positions[-1]['exit_time'] = row['time']\n",
    "        positions[-1]['pnl'] = profit - fee\n",
    "        position = None\n",
    "\n",
    "        if current_pnl + profit < max_pnl:\n",
    "            drawdown = current_pnl + profit - max_pnl\n",
    "            if drawdown < max_drawdown:\n",
    "                max_drawdown = drawdown\n",
    "                max_drawdown_time = row['time']\n",
    "\n",
    "    elif position == 'short':\n",
    "        exit_price = price\n",
    "        entry_price_pnl = last_pnl_price or entry_price\n",
    "        profit = (entry_price_pnl - exit_price) * ordersize / entry_price_pnl\n",
    "        fee = ordersize * trading_fees * 2 / 100\n",
    "        pnl.append({'time': row['time'], 'hourly_pnl': profit - fee})\n",
    "        last_pnl_price = exit_price\n",
    "\n",
    "        # --- Close open position for summary stats ---\n",
    "        profit = (entry_price - exit_price) * ordersize / entry_price\n",
    "        positions[-1]['exit'] = exit_price\n",
    "        positions[-1]['exit_time'] = row['time']\n",
    "        positions[-1]['pnl'] = profit - fee\n",
    "        position = None\n",
    "\n",
    "        if current_pnl + profit < max_pnl:\n",
    "            drawdown = current_pnl + profit - max_pnl\n",
    "            if drawdown < max_drawdown:\n",
    "                max_drawdown = drawdown\n",
    "                max_drawdown_time = row['time']\n",
    "        \n",
    "\n",
    "    # --- Create DataFrames for trades and PnL ---\n",
    "    trades_df = pd.DataFrame(positions)\n",
    "    pnl_df = pd.DataFrame(pnl)\n",
    "\n",
    "    # --- Time conversion for plotting ---\n",
    "    pnl_df['time'] = pd.to_datetime(pnl_df['time'])\n",
    "    pnl_df.set_index('time', inplace=True)\n",
    "    pnl_df['time'] = pnl_df.index\n",
    "\n",
    "    stock_pnl_dfs_2.append(pnl_df)\n",
    "\n",
    "    # --- Return calculations ---\n",
    "    pnl_df['hourly_return'] = pnl_df['hourly_pnl'] / 100\n",
    "    pnl_df['gross_return'] = 1 + pnl_df['hourly_return']\n",
    "    total_return = pnl_df['gross_return'].prod() - 1\n",
    "\n",
    "    # --- Daily returns and Sharpe ratio ---\n",
    "    daily_returns = pnl_df['gross_return'].resample('1D').prod() - 1\n",
    "    excess_daily_returns = daily_returns - risk_free_daily\n",
    "    mean_daily = excess_daily_returns.mean()\n",
    "    std_daily = excess_daily_returns.std()\n",
    "    sharpe = mean_daily / std_daily\n",
    "    sharpe_annual = sharpe * np.sqrt(252)\n",
    "\n",
    "    # --- Summary statistics ---\n",
    "    total_pnl = pnl_df['hourly_pnl'].sum()\n",
    "    num_trades = len(positions)\n",
    "    avg_pnl = total_pnl / num_trades if num_trades > 0 else 0\n",
    "    buynhold = (closePrice - openPrice) * ordersize / openPrice\n",
    "\n",
    "    pnl_all += total_pnl\n",
    "    buyNhold_pnl_all += buynhold\n",
    "\n",
    "    winning_trades = trades_df[trades_df['pnl'] > 0]\n",
    "    total_winning_trades += len(winning_trades)\n",
    "    win_rate = (len(winning_trades) / num_trades) * 100 if num_trades > 0 else 0\n",
    "\n",
    "    # --- Print summary for each stock ---\n",
    "    print(f\"Stock: {stock_id}\")\n",
    "    print(f\"Total PnL: {total_pnl:.2f}\")\n",
    "    print(f\"Max Drawdown: {max_drawdown:.2f}\")\n",
    "    print(f\"Max Drawdown Date: {max_drawdown_time}\")\n",
    "    print(f\"Buy & Hold PnL: {buynhold:.2f}\")\n",
    "    print(f\"Win Rate: {win_rate:.2f}%\")\n",
    "    print(f\"Number of Trades: {num_trades}\")\n",
    "    print(\"Annualized Sharpe:\", round(sharpe_annual, 3))\n",
    "    print(f\"Total Fees: {(num_trades * 2 * ordersize * trading_fees / 100):.2f}\")\n",
    "    print(f\"Last Date: {df_stock['time'].iloc[-1]}\")\n",
    "    print('')\n",
    "\n",
    "    \n",
    "    total_trades += num_trades\n",
    "    max_drawdown_list.append(max_drawdown)\n",
    "\n",
    "    # --- Visualization: plot price, trades, and cumulative PnL ---\n",
    "    if num_charts < max_num_charts:\n",
    "        cumulative_pnl = pnl_df['hourly_pnl'].cumsum()\n",
    "        positions_df = pd.DataFrame(positions)\n",
    "\n",
    "        # Extract entry/exit for long/short trades\n",
    "        long_entries = positions_df[positions_df['type'] == 'long']\n",
    "        long_exits = long_entries[long_entries['exit'].notna()]\n",
    "        short_entries = positions_df[positions_df['type'] == 'short']\n",
    "        short_exits = short_entries[short_entries['exit'].notna()]\n",
    "\n",
    "        fig, ax1 = plt.subplots(figsize=(12, 4))\n",
    "        ax1.set_title(f\"{stock_id} - Token Price & Cumulative PnL - Supertrend indicator\")\n",
    "        ax1.plot(df_stock['time'], df_stock['open'], color='black', label='Price')\n",
    "        ax1.set_ylabel('Token Price', color='black')\n",
    "        ax1.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "        # Shade long/short position periods\n",
    "        for _, row in long_exits.iterrows():\n",
    "            ax1.axvspan(row['time'], row['exit_time'], color='green',\n",
    "                        alpha=0.4 if row['pnl'] > 0 else 0.1,\n",
    "                        label='Active Long Position' if _ == 0 else None)\n",
    "        for _, row in short_exits.iterrows():\n",
    "            ax1.axvspan(row['time'], row['exit_time'], color='red',\n",
    "                        alpha=0.4 if row['pnl'] > 0 else 0.1,\n",
    "                        label='Active Short Position' if _ == 0 else None)\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(pnl_df['time'], cumulative_pnl, color='blue', label='Cumulative PnL', drawstyle='steps-post')\n",
    "        ax2.set_ylabel('Cumulative PnL', color='blue')\n",
    "        ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "        # Plot trade entry/exit markers\n",
    "        ax1.scatter(long_entries['time'], long_entries['entry'], marker='^', color='green', label='Long Entry', s=40)\n",
    "        ax1.scatter(long_exits['exit_time'], long_exits['exit'], marker='v', color='red', label='Long Exit', s=40)\n",
    "        ax1.scatter(short_entries['time'], short_entries['entry'], marker='v', color='red', label='Short Entry', s=40)\n",
    "        ax1.scatter(short_exits['exit_time'], short_exits['exit'], marker='^', color='green', label='Short Exit', s=40)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    num_charts += 1\n",
    "    \n",
    "# --- Portfolio summary statistics ---\n",
    "total_win_rate = (total_winning_trades / total_trades) * 100 if total_trades > 0 else 0\n",
    "\n",
    "print(f\"Total PnL: {pnl_all:.2f}\")\n",
    "print(f\"Average PnL: {pnl_all / total_count:.2f}\")\n",
    "print(f\"Average Max Drawdown: {sum(max_drawdown_list) / len(max_drawdown_list):.2f}\")\n",
    "print(f\"Buy & Hold Average PnL: {buyNhold_pnl_all / total_count:.2f}\")\n",
    "print(f\"Total Trades: {total_trades}\")\n",
    "print(f\"Win Rate: {total_win_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba6fc26",
   "metadata": {},
   "source": [
    "## 16. Portfolio Return Aggregation & Visualization (Supertrend Only)\n",
    "\n",
    "Aggregates returns across all stocks, plots equity curve and drawdown, and summarizes portfolio statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Portfolio-Level PnL Aggregation and Performance Evaluation ---\n",
    "\n",
    "# Initialize list to hold hourly PnL series for each stock (in %)\n",
    "stock_returns = []\n",
    "\n",
    "# Extract and align hourly PnL for each stock\n",
    "for i, df in enumerate(stock_pnl_dfs_2):\n",
    "    df = df.copy()\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df.drop_duplicates(subset='time')  # Ensure unique timestamps\n",
    "    df.set_index('time', inplace=True)\n",
    "\n",
    "    df[f'pnl_stock_{i}'] = df['hourly_pnl']  # Already in %\n",
    "    stock_returns.append(df[[f'pnl_stock_{i}']])\n",
    "\n",
    "# Combine all stock PnL time series into one DataFrame\n",
    "portfolio_df = pd.concat(stock_returns, axis=1).fillna(0)\n",
    "\n",
    "# Compute equal-weighted portfolio hourly return (in %) \n",
    "portfolio_df['portfolio_hourly_return'] = portfolio_df.mean(axis=1) \n",
    "\n",
    "# Calculate cumulative PnL over time (in %) \n",
    "portfolio_df['cumulative_pnl_percent'] = portfolio_df['portfolio_hourly_return'].cumsum()\n",
    "\n",
    "# -- Calculate daily returns and Sharpe ratio --\n",
    "# Convert hourly returns to gross returns for compounding\n",
    "portfolio_df['gross_return'] = 1 + portfolio_df['portfolio_hourly_return'] / 100\n",
    "\n",
    "# Resample to daily gross returns and compute daily return\n",
    "daily_returns = portfolio_df['gross_return'].resample('1D').prod() - 1\n",
    "\n",
    "# Excess return over risk-free rate (daily)\n",
    "excess_daily_returns = daily_returns - risk_free_daily\n",
    "mean_excess = excess_daily_returns.mean()\n",
    "std_excess = excess_daily_returns.std()\n",
    "\n",
    "# Daily and annualized Sharpe ratio\n",
    "sharpe_daily = mean_excess / std_excess\n",
    "sharpe_annual = sharpe_daily * np.sqrt(252)\n",
    "\n",
    "# Compute drawdown from cumulative PnL \n",
    "# Start from 100 to simulate a normalized capital base\n",
    "cumulative = portfolio_df['cumulative_pnl_percent'] + 100\n",
    "rolling_max = cumulative.cummax()\n",
    "drawdown = (cumulative - rolling_max) / rolling_max\n",
    "portfolio_df['drawdown'] = drawdown\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
    "\n",
    "# Plot equity curve\n",
    "axes[0].plot(portfolio_df.index, portfolio_df['cumulative_pnl_percent'], color='blue', label='Cumulative PnL (%)')\n",
    "axes[0].set_title(\"Portfolio Cumulative PnL Over Time\")\n",
    "axes[0].set_ylabel(\"Cumulative PnL (%)\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot drawdown\n",
    "axes[1].plot(portfolio_df.index, portfolio_df['drawdown'] * 100, color='red', label='Drawdown (%)')\n",
    "axes[1].set_title(\"Portfolio Drawdown Over Time\")\n",
    "axes[1].set_xlabel(\"Time\")\n",
    "axes[1].set_ylabel(\"Drawdown (%)\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print performance summary \n",
    "final_pnl = portfolio_df['cumulative_pnl_percent'].iloc[-1]\n",
    "\n",
    "print(f\"Annualized Sharpe Ratio : {sharpe_annual:.3f}\")\n",
    "print(f\"Maximum Drawdown        : {max_drawdown * 100:.2f}%\")\n",
    "print(f\"Total Cumulative PnL    : {final_pnl:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b915f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
